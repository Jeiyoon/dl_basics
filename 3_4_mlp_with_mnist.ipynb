{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-4_mlp_with_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3vhQwHUpMe-"
      },
      "source": [
        "# trouble shooting (email: k4ke@korea.ac.kr)\n",
        "\n",
        "1)\n",
        "https://hashcode.co.kr/questions/8421/밑바닥부터-시작하는-딥러닝-3장-mnist-다운로드-관련\n",
        "\n",
        "https://github.com/WegraLee/deep-learning-from-scratch\n",
        "\n",
        "2) unresolved(2020.12.28)\n",
        "\n",
        "acuuracy가 14% 나오는 이유?\n",
        "\n",
        "-> y = [nan, ...]\n",
        "\n",
        "-> pycharm 디버거 모드로 값 찍어봐야 될듯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SoECQYplEao",
        "outputId": "fec4c537-fb7b-4118-912c-a819cdb4038f"
      },
      "source": [
        "# coding: utf-8\n",
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('You should use Python 3.x')\n",
        "import os.path\n",
        "import gzip\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
        "key_file = {\n",
        "    'train_img':'train-images-idx3-ubyte.gz',\n",
        "    'train_label':'train-labels-idx1-ubyte.gz',\n",
        "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
        "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "dataset_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
        "save_file = dataset_dir + \"/mnist.pkl\"\n",
        "\n",
        "train_num = 60000\n",
        "test_num = 10000\n",
        "img_dim = (1, 28, 28)\n",
        "img_size = 784\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print(\"Downloading \" + file_name + \" ... \")\n",
        "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "    print(\"Done\")\n",
        "    \n",
        "def download_mnist():\n",
        "    for v in key_file.values():\n",
        "       _download(v)\n",
        "        \n",
        "def _load_label(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return labels\n",
        "\n",
        "def _load_img(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1, img_size)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return data\n",
        "    \n",
        "def _convert_numpy():\n",
        "    dataset = {}\n",
        "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])    \n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def init_mnist():\n",
        "    download_mnist()\n",
        "    dataset = _convert_numpy()\n",
        "    print(\"Creating pickle file ...\")\n",
        "    with open(save_file, 'wb') as f:\n",
        "        pickle.dump(dataset, f, -1)\n",
        "    print(\"Done!\")\n",
        "\n",
        "def _change_one_hot_label(X):\n",
        "    T = np.zeros((X.size, 10))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "        \n",
        "    return T\n",
        "    \n",
        "\n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
        "    \"\"\"MNIST 데이터셋 읽기\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    normalize : 이미지의 픽셀 값을 0.0~1.0 사이의 값으로 정규화할지 정한다.\n",
        "    one_hot_label : \n",
        "        one_hot_label이 True면、레이블을 원-핫(one-hot) 배열로 돌려준다.\n",
        "        one-hot 배열은 예를 들어 [0,0,1,0,0,0,0,0,0,0]처럼 한 원소만 1인 배열이다.\n",
        "    flatten : 입력 이미지를 1차원 배열로 만들지를 정한다. \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_file):\n",
        "        init_mnist()\n",
        "        \n",
        "    with open(save_file, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    \n",
        "    if normalize:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].astype(np.float32)\n",
        "            dataset[key] /= 255.0\n",
        "            \n",
        "    if one_hot_label:\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])    \n",
        "    \n",
        "    if not flatten:\n",
        "         for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
        "\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \n",
        "\n",
        "def sigmoid(z):\n",
        "  return 1 / 1 + np.exp(-z)\n",
        "\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - np.max(x) # 오버플로 대책\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "def get_data():\n",
        "  (x_train, t_train), (x_test, t_test) = load_mnist(normalize= True, flatten = True, one_hot_label = False)\n",
        "\n",
        "  print(x_test.shape)\n",
        "  print(t_test.shape)\n",
        "\n",
        "  return x_test, t_test\n",
        "\n",
        "def init_network():\n",
        "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
        "        network = pickle.load(f)\n",
        "    \n",
        "    # print(network)\n",
        "\n",
        "    return network\n",
        "\n",
        "def predict(network, x):\n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    z2 = sigmoid(a2)\n",
        "    a3 = np.dot(z2, W3) + b3\n",
        "    y = softmax(a3)\n",
        "\n",
        "    return y\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    init_mnist()\n",
        "\n",
        "    x, t = get_data()\n",
        "    network = init_network()\n",
        "    accuracy_cnt = 0\n",
        "    cnt = 0\n",
        "    for i in range(len(x)):\n",
        "        cnt += 1\n",
        "        y = predict(network, x[i])\n",
        "        if cnt < 10:\n",
        "          print(y)\n",
        "          print(t[i])\n",
        "          print(\"###\")\n",
        "        p = np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
        "        if p == t[i]:\n",
        "            accuracy_cnt += 1   \n",
        "    print(accuracy_cnt)\n",
        "    print(cnt)\n",
        "    "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n",
            "(10000, 784)\n",
            "(10000,)\n",
            "[nan nan nan nan nan nan nan nan nan nan]\n",
            "7\n",
            "###\n",
            "[nan nan nan nan nan nan nan nan nan nan]\n",
            "2\n",
            "###\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "1\n",
            "###\n",
            "[nan nan nan nan nan nan nan nan nan nan]\n",
            "0\n",
            "###\n",
            "[nan nan nan nan nan nan nan nan nan nan]\n",
            "4\n",
            "###\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "1\n",
            "###\n",
            "[nan nan nan nan nan nan nan nan nan nan]\n",
            "4\n",
            "###\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "9\n",
            "###\n",
            "[nan nan nan nan nan nan nan nan nan nan]\n",
            "5\n",
            "###\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:128: RuntimeWarning: overflow encountered in exp\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: RuntimeWarning: invalid value encountered in subtract\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: RuntimeWarning: overflow encountered in subtract\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1438\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "QLwVVEyWdgb5",
        "outputId": "530b9064-26d2-48c0-fcac-27b3deec187a"
      },
      "source": [
        "\"\"\"\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from PIL import Image\n",
        "\n",
        "# def img_show(img):\n",
        "#     pil_img = Image.fromarray(np.uint8(img))\n",
        "#     pil_img.show()\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten = True, normalize = False)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)\n",
        "print(x_test.shape)\n",
        "print(t_test.shape)\n",
        "\n",
        "img = x_train[0]\n",
        "label = t_train[0]\n",
        "print(label)  # 5\n",
        "\n",
        "print(img.shape)  # (784,) / flattened\n",
        "img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
        "print(img.shape)  # (28, 28)\n",
        "\n",
        "# img_show(img)\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport sys, os\\nsys.path.append(os.pardir)\\n\\nimport numpy as np\\n# import matplotlib.pyplot as plt\\n# from PIL import Image\\n\\n# def img_show(img):\\n#     pil_img = Image.fromarray(np.uint8(img))\\n#     pil_img.show()\\n\\n(x_train, t_train), (x_test, t_test) = load_mnist(flatten = True, normalize = False)\\n\\nprint(x_train.shape)\\nprint(t_train.shape)\\nprint(x_test.shape)\\nprint(t_test.shape)\\n\\nimg = x_train[0]\\nlabel = t_train[0]\\nprint(label)  # 5\\n\\nprint(img.shape)  # (784,) / flattened\\nimg = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\\nprint(img.shape)  # (28, 28)\\n\\n# img_show(img)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}